<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>rayanon - Software</title><link href="/" rel="alternate"></link><link href="/feeds/software.atom.xml" rel="self"></link><id>/</id><updated>2018-12-10T11:40:00+05:30</updated><subtitle>Musings of a human existence</subtitle><entry><title>Manage the behemoth of HaskellÂ wreq</title><link href="/haskell-wreq-http-manager.html" rel="alternate"></link><published>2018-12-10T11:40:00+05:30</published><updated>2018-12-10T11:40:00+05:30</updated><author><name>Anon Ray</name></author><id>tag:None,2018-12-10:/haskell-wreq-http-manager.html</id><summary type="html">&lt;p&gt;While Haskell&amp;#8217;s wreq is great a library, but using it unknowingly can have pitfalls. If you&amp;#8217;re not using a session manager, it can take up a lot of memory and even lead to &lt;span class="caps"&gt;TCP&lt;/span&gt; socket&amp;nbsp;leaks.&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you have ever needed to make &lt;span class="caps"&gt;HTTP&lt;/span&gt; requests from your Haskell code, chances
are that you have used the &lt;a href="http://hackage.haskell.org/package/wreq"&gt;wreq&lt;/a&gt;
library. If your work was a one-off job, or you have been using it only for one
or two requests or infrequently, you might not have noticed that wreq needs
managing once you are making a lot of network&amp;nbsp;requests.&lt;/p&gt;
&lt;p&gt;In my workplace deployments, backend services make lots of &lt;span class="caps"&gt;HTTP&lt;/span&gt; requests.
Specifically, they make multiple &lt;span class="caps"&gt;HTTP&lt;/span&gt; requests to the same server, and there are
a group of servers that they talk to. For example, we make requests to Google,
&lt;span class="caps"&gt;AWS&lt;/span&gt;, Azure and Digital Ocean cloud services, and to each we make multiple
requests. I have noticed, if you do not use a &lt;span class="caps"&gt;HTTP&lt;/span&gt; session manager when making
network requests of the above pattern using wreq, it&amp;nbsp;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;tends to use up significant memory, probably due to keeping so many &lt;span class="caps"&gt;TCP&lt;/span&gt;
   connections&amp;nbsp;open&lt;/li&gt;
&lt;li&gt;tends to perform not so efficiently (tends to be slower), because it would
   setup and teardown an entire &lt;span class="caps"&gt;TCP&lt;/span&gt; connection for every&amp;nbsp;request&lt;/li&gt;
&lt;li&gt;can even lead to &lt;span class="caps"&gt;TCP&lt;/span&gt; socket leaks (&lt;a href="https://blog.hasura.io/debugging-tcp-socket-leak-in-a-kubernetes-cluster-99171d3e654b"&gt;read
   more&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Usually browsers and other popular &lt;span class="caps"&gt;HTTP&lt;/span&gt; clients automatically manage the above
by keeping &lt;span class="caps"&gt;TCP&lt;/span&gt; connections open and re-using them. But in &lt;code&gt;wreq&lt;/code&gt; you have to be
explicit about&amp;nbsp;them.&lt;/p&gt;
&lt;h3&gt;Using wreq&amp;#8217;s session&amp;nbsp;manager&lt;/h3&gt;
&lt;p&gt;wreq has a &lt;code&gt;Network.Wreq.Session&lt;/code&gt; module, which exposes a &lt;span class="caps"&gt;HTTP&lt;/span&gt; session manager.
The &lt;span class="caps"&gt;API&lt;/span&gt; is straight-forward, and is used like&amp;nbsp;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;import&lt;/span&gt;           &lt;span class="nn"&gt;Network.Wreq&lt;/span&gt;
&lt;span class="kr"&gt;import&lt;/span&gt;           &lt;span class="nn"&gt;Network.Wreq.Session&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kr"&gt;import&lt;/span&gt; &lt;span class="k"&gt;qualified&lt;/span&gt; &lt;span class="nn"&gt;Network.Wreq.Session&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;Sess&lt;/span&gt;

&lt;span class="nf"&gt;main&lt;/span&gt; &lt;span class="ow"&gt;::&lt;/span&gt; &lt;span class="kt"&gt;IO&lt;/span&gt; &lt;span class="nb"&gt;()&lt;/span&gt;
&lt;span class="nf"&gt;main&lt;/span&gt; &lt;span class="ow"&gt;=&lt;/span&gt; &lt;span class="kr"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;sess&lt;/span&gt;  &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;Sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newSession&lt;/span&gt;
  &lt;span class="n"&gt;resp&lt;/span&gt;  &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;mkGetRequest&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt;
  &lt;span class="n"&gt;resp2&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;mkAnotherRequest&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt;

&lt;span class="nf"&gt;mkGetRequest&lt;/span&gt; &lt;span class="ow"&gt;::&lt;/span&gt; &lt;span class="kt"&gt;Session&lt;/span&gt; &lt;span class="ow"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;IO&lt;/span&gt; &lt;span class="kt"&gt;ByteString&lt;/span&gt;
&lt;span class="nf"&gt;mkGetRequest&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="ow"&gt;=&lt;/span&gt; &lt;span class="kr"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;resp&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;Sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://httpbin.org/get&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;return&lt;/span&gt; &lt;span class="n"&gt;resp&lt;/span&gt;

&lt;span class="nf"&gt;mkAnotherRequest&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="ow"&gt;=&lt;/span&gt; &lt;span class="kr"&gt;do&lt;/span&gt;
  &lt;span class="kt"&gt;Sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://httpbin.org/get&amp;quot;&lt;/span&gt;
  &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The wreq documentation recommends to use the manager if you&amp;#8217;re making multiple
requests to the same server so that it can re-use &lt;span class="caps"&gt;TCP&lt;/span&gt; connections. But this
documentation is hidden away in the &lt;code&gt;Session&lt;/code&gt; module separate from the other
main modules. That is why it is easy to overlook&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;Also, the &lt;code&gt;newSession&lt;/code&gt; &lt;span class="caps"&gt;API&lt;/span&gt; creates a manager that manages cookies as well. That
is, any cookie sent by a server is sent back across requests (how browsers
behave) when using the same manager. This is not really desirable in backend
systems unless you&amp;#8217;re dealing with having a user session. Wreq exposes another
&lt;span class="caps"&gt;API&lt;/span&gt; called &lt;code&gt;newAPISession&lt;/code&gt;. The &lt;span class="caps"&gt;API&lt;/span&gt; usage is exactly same as &lt;code&gt;newSession&lt;/code&gt; but
this just a &lt;span class="caps"&gt;HTTP&lt;/span&gt; manager without managing any of the&amp;nbsp;cookies.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;import&lt;/span&gt;           &lt;span class="nn"&gt;Network.Wreq&lt;/span&gt;
&lt;span class="kr"&gt;import&lt;/span&gt; &lt;span class="k"&gt;qualified&lt;/span&gt; &lt;span class="nn"&gt;Network.Wreq.Session&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;Sess&lt;/span&gt;

&lt;span class="nf"&gt;main&lt;/span&gt; &lt;span class="ow"&gt;=&lt;/span&gt; &lt;span class="kr"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;Sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newAPISession&lt;/span&gt;
  &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Underneath, wreq uses the &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;code&gt;Manager&lt;/code&gt; from the &lt;a href="https://hackage.haskell.org/package/http-client-0.5.10/docs/Network-HTTP-Client.html#t:Manager"&gt;http-client&lt;/a&gt; package for
sessions. You can use the &lt;code&gt;Manager&lt;/code&gt; directly from the &lt;code&gt;http-client&lt;/code&gt; package as&amp;nbsp;well.&lt;/p&gt;
&lt;h3&gt;Tidying things&amp;nbsp;up&lt;/h3&gt;
&lt;p&gt;Finally, you would obviously not define functions that take the &lt;code&gt;Session&lt;/code&gt;
explicitly in its argument. You should have a &lt;code&gt;Reader&lt;/code&gt; monad constraint on your
functions and make the the &lt;span class="caps"&gt;HTTP&lt;/span&gt; session manager as part of your environment. Something&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;import&lt;/span&gt;           &lt;span class="nn"&gt;Control.Monad.Reader&lt;/span&gt;
&lt;span class="kr"&gt;import&lt;/span&gt;           &lt;span class="nn"&gt;Network.Wreq.Session&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kr"&gt;import&lt;/span&gt; &lt;span class="k"&gt;qualified&lt;/span&gt; &lt;span class="nn"&gt;Network.Wreq.Session&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;Sess&lt;/span&gt;

&lt;span class="kr"&gt;type&lt;/span&gt; &lt;span class="kt"&gt;App&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="ow"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;ReaderT&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="kt"&gt;IO&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;

&lt;span class="nf"&gt;main&lt;/span&gt; &lt;span class="ow"&gt;::&lt;/span&gt; &lt;span class="kt"&gt;IO&lt;/span&gt; &lt;span class="nb"&gt;()&lt;/span&gt;
&lt;span class="nf"&gt;main&lt;/span&gt; &lt;span class="ow"&gt;=&lt;/span&gt; &lt;span class="kr"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;Sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newAPISession&lt;/span&gt;
  &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;flip&lt;/span&gt; &lt;span class="n"&gt;runReaderT&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="o"&gt;$&lt;/span&gt; &lt;span class="kr"&gt;do&lt;/span&gt;
    &lt;span class="n"&gt;resp&lt;/span&gt;  &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;mkGetRequest&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt;
    &lt;span class="n"&gt;resp2&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;mkAnotherRequest&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt;
  &lt;span class="n"&gt;putStrLn&lt;/span&gt; &lt;span class="o"&gt;$&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;

&lt;span class="nf"&gt;mkGetRequest&lt;/span&gt; &lt;span class="ow"&gt;::&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;MonadReader&lt;/span&gt; &lt;span class="kt"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;IO&lt;/span&gt; &lt;span class="kt"&gt;ByteString&lt;/span&gt;
&lt;span class="nf"&gt;mkGetRequest&lt;/span&gt; &lt;span class="ow"&gt;=&lt;/span&gt; &lt;span class="kr"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;ask&lt;/span&gt;
  &lt;span class="n"&gt;resp&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;Sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://httpbin.org/get&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;return&lt;/span&gt; &lt;span class="n"&gt;resp&lt;/span&gt;

&lt;span class="nf"&gt;mkAnotherRequest&lt;/span&gt; &lt;span class="ow"&gt;::&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;MonadReader&lt;/span&gt; &lt;span class="kt"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;IO&lt;/span&gt; &lt;span class="kt"&gt;ByteString&lt;/span&gt;
&lt;span class="nf"&gt;mkAnotherRequest&lt;/span&gt; &lt;span class="ow"&gt;=&lt;/span&gt; &lt;span class="kr"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;ask&lt;/span&gt;
  &lt;span class="kt"&gt;Sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://httpbin.org/get&amp;quot;&lt;/span&gt;
  &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wreq also has another problem. It throws exceptions when the response from the
server is a non-200 response. It also throws exceptions if the network
connection fails. In production code we need to handle this behaviour of &lt;code&gt;wreq&lt;/code&gt;
as well to make if safer. But that I&amp;#8217;ll probably discuss in another&amp;nbsp;post.&lt;/p&gt;
&lt;hr&gt;</content><category term="programming"></category><category term="haskell"></category><category term="wreq"></category></entry><entry><title>Backup strategies onÂ Postgres</title><link href="/postgres-backup.html" rel="alternate"></link><published>2017-03-25T04:08:00+05:30</published><updated>2017-03-25T04:08:00+05:30</updated><author><name>Anon Ray</name></author><id>tag:None,2017-03-25:/postgres-backup.html</id><summary type="html">&lt;p&gt;If you are using any database in production you should always have backups.
Servers can crash, disks can fail, data can get corrupted, people can make
mistakes; a lot of failures can happen with the production instance. Hence it
is extremely important to have backups on a production&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;In â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you are using any database in production you should always have backups.
Servers can crash, disks can fail, data can get corrupted, people can make
mistakes; a lot of failures can happen with the production instance. Hence it
is extremely important to have backups on a production&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;In this post I&amp;#8217;m going to discuss various backup options that are available on
&lt;a href="https://postgresql.org"&gt;PostgreSQL&lt;/a&gt; and the various ways one can configure taking backups of the
database in production. I&amp;#8217;ll also discuss in what situation what kind of
backups are more&amp;nbsp;useful.&lt;/p&gt;
&lt;p&gt;First, let&amp;#8217;s look at the various backup options available in&amp;nbsp;Postgres:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Logical&amp;nbsp;backups&lt;/li&gt;
&lt;li&gt;Physical&amp;nbsp;backups&lt;/li&gt;
&lt;li&gt;Continuous&amp;nbsp;backups&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let&amp;#8217;s look at each of these&amp;nbsp;below.&lt;/p&gt;
&lt;h3&gt;Logical&amp;nbsp;backups&lt;/h3&gt;
&lt;p&gt;Logical backups are dumps of &lt;span class="caps"&gt;SQL&lt;/span&gt; statements which describe the state of the
database. They can be obtained using a tool like &lt;code&gt;pg_dump&lt;/code&gt;. These dump files
are just &lt;span class="caps"&gt;SQL&lt;/span&gt; files. Hence, they can be imported to another postgres instance
using &lt;code&gt;psql&lt;/code&gt; normally. It is usually a good idea to take one logical backup
before altering schema or migrating a&amp;nbsp;database.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ pg_dump -U admin -h db.example.com mydatabase &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;gt&lt;span class="p"&gt;;&lt;/span&gt; dump.sql
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The file &lt;code&gt;dump.sql&lt;/code&gt; is your backup. To recover it, run this in another&amp;nbsp;database:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ psql -U admin -h db2.example.com mydatabase &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;lt&lt;span class="p"&gt;;&lt;/span&gt; dump.sql
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;-U&lt;/code&gt; takes the postgres username. Port can also be specified via &lt;code&gt;-p&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Physical&amp;nbsp;backups&lt;/h3&gt;
&lt;p&gt;Physical backups are backups via the filesystem. Meaning they can be snapshots
of the filesystem itself, or they could be just copies of the Postgres
database&amp;#8217;s data directory. The entire database instance&amp;#8217;s state is stored in
Postgres&amp;#8217; data directory; which is usually &lt;code&gt;/var/lib/postgresql/&amp;lt;VERSION&amp;gt;/data&lt;/code&gt;
on *nix&amp;nbsp;machines.&lt;/p&gt;
&lt;p&gt;You can use &lt;code&gt;rsync&lt;/code&gt; to periodically take backup of this data directory, and
then store the backup&amp;nbsp;elsewhere.&lt;/p&gt;
&lt;p&gt;As an&amp;nbsp;example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ tar czf mydb-pgdata-21022017-1803.tar.gz  /var/lib/postgresql/9.6/data
$ rsync --progress --partial --recursive mydb-pgdata-21022017-1803.tar.gz &lt;span class="se"&gt;\&lt;/span&gt;
    backup@backup-server.example.com:/vol/pgdata_backups/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We first make a compressed (gzipped) tarball of the data directory, and then
use &lt;code&gt;rsync&lt;/code&gt; to copy the files to our backup&amp;nbsp;server.&lt;/p&gt;
&lt;h3&gt;Continuous&amp;nbsp;backups&lt;/h3&gt;
&lt;p&gt;Continuous backups are an advanced feature of Postgres. Postgres database has
this design where it first commits a transaction a file on the disk, called the
Write-ahead Log (or &lt;span class="caps"&gt;WAL&lt;/span&gt;), and waits for the data to be actually written to the
disk; and only then commits the transaction to the current database object.
This way even if a Postgres server crashes in the middle of a transaction, it
will never have inconsistent state and when it recovers it can replay the &lt;span class="caps"&gt;WAL&lt;/span&gt;
to arrive at the state it was when it&amp;nbsp;crashed.&lt;/p&gt;
&lt;p&gt;If you think about it, this amazing &lt;span class="caps"&gt;WAL&lt;/span&gt; design results in a uber-amazing backup
system. These &lt;span class="caps"&gt;WAL&lt;/span&gt; logs can simply copied or streamed over to another machine
where&amp;nbsp;-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;it can be kept as a backup - and this enables us to recover a Postgres
   database in any point in time. Just ask Postgres replay to that point in the
   &lt;span class="caps"&gt;WAL&lt;/span&gt; where you fancy. This also called a Point-in-time recovery (&lt;span class="caps"&gt;PITR&lt;/span&gt;) in &lt;span class="caps"&gt;DB&lt;/span&gt;&amp;nbsp;world.&lt;/li&gt;
&lt;li&gt;it can be replayed to a secondary Postgres instance and then this instance
   can be used as a slave, a replicated instance, a backup or even a secondary
   read-only&amp;nbsp;instance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Using the &lt;span class="caps"&gt;WAL&lt;/span&gt;, a lot of interesting things can be done like streaming
replication, hot standby failover instance, read-only slaves and few more.
Maybe I will write about these interesing bits in a future&amp;nbsp;post.&lt;/p&gt;
&lt;p&gt;Configuring continous backups is little more involved and probably will require
its own post and hence I will not cover configuration of continous backups
here. You can search about it on the internet. But I can suggest using &lt;a href="https://github.com/wal-e/wal-e"&gt;&lt;span class="caps"&gt;WAL&lt;/span&gt;-E&lt;/a&gt;,
which is a fantastic tool that makes setting up continous backup very easy.
Once you install and configure &lt;span class="caps"&gt;WAL&lt;/span&gt;-E it can stream your backup files to S3,
Google bucket, Azure&amp;nbsp;etc.&lt;/p&gt;
&lt;h3&gt;But which backup to use&amp;nbsp;where?&lt;/h3&gt;
&lt;p&gt;Now, the natural next question is which backup method to use. Should someone
use all the possible methods, or sticking to one method is good&amp;nbsp;enough?&lt;/p&gt;
&lt;p&gt;It can be confusing or daunting to look at so many options. Hence, I&amp;#8217;m here to
nudge you in the right direction with the right ideas. But don&amp;#8217;t take my ideas
for granted. Do your own research, think through your problems, and come up
with your own&amp;nbsp;conclusion.&lt;/p&gt;
&lt;p&gt;Almost in all situations continuous backup makes sense. It offers a streaming,
continuous backup of your production database and it also offers
Point-in-time-recovery. &lt;span class="caps"&gt;PITR&lt;/span&gt; can be very valuable, because it let&amp;#8217;s you specify
a timestamp and recover to it. Although, setting up backup and recovery
mechanism in this method is little more complicated - as there can be few edge
cases, specially regarding the process you will adapt to do recovery. Hence,
this method requires a bit of planning and hence takes more effort overall. But
probably also pays the best in the long&amp;nbsp;run.&lt;/p&gt;
&lt;p&gt;Filesystem level backups are error-prone, there is no guarantee that you get a
consistent snapshot. What if the moment when you were taking the snapshot of
the underlying filesystem, the database decided to write some new data. There
is no way for you to control that. Also by moving around the filesystem for our
backups, we are essentially not leveraging what the database can do for us.
Hence, for most of the cases filesystem backups can be ignored. If you are
really paranoid and want to keep redundant backups, sure go ahead and setup a
cronjob to rsync your &lt;span class="caps"&gt;PGDATA&lt;/span&gt; directory somewhere&amp;nbsp;safe. &lt;/p&gt;
&lt;p&gt;Logical backups give you a logical snapshot of your database. Logical snapshots
are tremendously useful if you are migrating your database. Its always a good
idea when you are migrating a schema, that you take a logical backup before
migrating. It is also useful for debugging purposes. You can look at two
different logical dumps and compare them to figure out data discrepancies.
It&amp;#8217;s not a bad idea to add a cronjob which takes a &lt;code&gt;pg_dump&lt;/code&gt; periodically,
along with your continuous backup configuration. That way you have a logical
snapshot of your database and you have redundant backups. Win-win&amp;nbsp;situation!&lt;/p&gt;
&lt;p&gt;On closing note, another important aspect of database backup and recovery
process is to always validate and check that current backups are happening and
are working - i.e from existing backups database can be recovered. In the light
of the recent Gitlab incident this has become even more apparent, that systems
fail and assumptions don&amp;#8217;t hold true always. Do not rely on the fact that you
have setup the system correctly 2 years back. As an &lt;span class="caps"&gt;DBA&lt;/span&gt; or admin it is not just
enough to setup a backup system, one should regularly monitor the backups and
also perform periodic drills, where they take one of the latest backups and try
to recover from&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Backup systems are generally long running systems and people usually forget
about them right after configuring them; because they do not need to touch that
system in a long time. But eventually the day comes when they have recover from
the backups, and they can only hope that their backups are safe and somehow
magically working even if they have gone throuhg system/software failures,
hardware failure, data corruption and what&amp;nbsp;not.&lt;/p&gt;
&lt;p&gt;Hence knowing the status of the backups can make the difference of a world to
the application because after all the most important part of any application is
the&amp;nbsp;database.&lt;/p&gt;</content><category term="postgres"></category><category term="backups"></category><category term="sysadmin"></category></entry></feed>